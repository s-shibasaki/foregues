{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from foregues.dataset import ForeguesDataset\n",
    "from foregues.models import ForeguesModel\n",
    "\n",
    "# ロギング設定\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# デバイス設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用デバイス: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "data = pd.read_csv(\n",
    "    'data/histdata/HISTDATA_COM_ASCII_EURUSD_M1_2023/DAT_ASCII_EURUSD_M1_2023.csv',\n",
    "    header=None,\n",
    "    index_col='timestamp',\n",
    "    delimiter=';',\n",
    "    names=['timestamp', 'open', 'high', 'low', 'close', 'volume'],\n",
    "    parse_dates=['timestamp'],\n",
    "    date_format='%Y%m%d %H%M%S'\n",
    ")\n",
    "\n",
    "# 5分足にリサンプリング\n",
    "resampled_data = data.resample('5min').agg({\n",
    "    'open': 'first',\n",
    "    'high': 'max',\n",
    "    'low': 'min',\n",
    "    'close': 'last',\n",
    "    'volume': 'sum'\n",
    "}).dropna()\n",
    "\n",
    "print(f\"リサンプリング後のデータサイズ: {len(resampled_data)}\")\n",
    "print(f\"データ期間: {resampled_data.index[0]} から {resampled_data.index[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ設定\n",
    "TH1 = 0.0030  # 30 pips\n",
    "TH2 = 0.0040  # 40 pips\n",
    "SEQUENCE_LENGTH = 1440  # 5日間\n",
    "PREDICTION_PERIOD = 288  # 24時間\n",
    "\n",
    "print(f\"閾値設定: th1={TH1} ({TH1*10000:.1f}pips), th2={TH2} ({TH2*10000:.1f}pips)\")\n",
    "print(f\"シーケンス長: {SEQUENCE_LENGTH} (約{SEQUENCE_LENGTH//288:.1f}日)\")\n",
    "print(f\"予測期間: {PREDICTION_PERIOD} (約{PREDICTION_PERIOD//12:.1f}時間)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの作成\n",
    "dataset = ForeguesDataset(\n",
    "    data=resampled_data,\n",
    "    th1=TH1,\n",
    "    th2=TH2,\n",
    "    sequence_length=SEQUENCE_LENGTH,\n",
    "    prediction_period=PREDICTION_PERIOD\n",
    ")\n",
    "\n",
    "print(f\"データセットサイズ: {len(dataset)}\")\n",
    "\n",
    "# ラベル分布の確認\n",
    "labels = [dataset[i]['labels'] for i in range(len(dataset))]\n",
    "label_counts = np.bincount(labels, minlength=3)\n",
    "print(f\"ラベル分布:\")\n",
    "print(f\"  クラス0 (何もしない): {label_counts[0]} ({label_counts[0]/len(labels)*100:.1f}%)\")\n",
    "print(f\"  クラス1 (買い): {label_counts[1]} ({label_counts[1]/len(labels)*100:.1f}%)\")\n",
    "print(f\"  クラス2 (売り): {label_counts[2]} ({label_counts[2]/len(labels)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルパラメータの設定\n",
    "model_params = {\n",
    "    'sequence_names': ['price_history'],\n",
    "    'feature_aliases': {},  # 特徴量のエイリアス設定\n",
    "    'numerical_features': dataset.numerical_features,\n",
    "    'categorical_features': dataset.get_categorical_vocab_sizes(),\n",
    "    'num_classes': 3,\n",
    "    'd_token': 192,\n",
    "    'num_bins': 8,\n",
    "    'binning_temperature': 0.8,\n",
    "    'binning_init_range': 2.5,\n",
    "    'ft_n_layers': 3,\n",
    "    'ft_n_heads': 8,\n",
    "    'seq_n_layers': 3,\n",
    "    'seq_n_heads': 8,\n",
    "    'dropout': 0.1\n",
    "}\n",
    "\n",
    "print(\"モデル設定:\")\n",
    "for key, value in model_params.items():\n",
    "    if key not in ['numerical_features', 'categorical_features']:\n",
    "        print(f\"  {key}: {value}\")\n",
    "print(f\"  数値特徴量数: {len(model_params['numerical_features'])}\")\n",
    "print(f\"  カテゴリ特徴量数: {len(model_params['categorical_features'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの分割 (訓練:検証:テスト = 70:15:15)\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"データ分割:\")\n",
    "print(f\"  訓練データ: {len(train_dataset)}\")\n",
    "print(f\"  検証データ: {len(val_dataset)}\")\n",
    "print(f\"  テストデータ: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データローダーの作成\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"データローダー作成完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの作成\n",
    "model = ForeguesModel(**model_params)\n",
    "model = model.to(device)\n",
    "\n",
    "# モデルサイズの確認\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"モデル作成完了\")\n",
    "print(f\"総パラメータ数: {total_params:,}\")\n",
    "print(f\"訓練可能パラメータ数: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数とオプティマイザーの設定\n",
    "# クラス不均衡を考慮した重み付き交差エントロピー損失\n",
    "class_weights = torch.tensor([1.0, 2.0, 2.0], dtype=torch.float32).to(device)  # クラス0を軽く、1,2を重く\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# オプティマイザー\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5,\n",
    "    betas=(0.9, 0.999)\n",
    ")\n",
    "\n",
    "# 学習率スケジューラー\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "print(\"損失関数・オプティマイザー設定完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練ループ\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        x_num = batch['x_num']\n",
    "        x_cat = batch['x_cat'] \n",
    "        sequence_data = batch['sequence_data']\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # GPU転送\n",
    "        if x_num:\n",
    "            x_num = {k: v.to(device) for k, v in x_num.items()}\n",
    "        if x_cat:\n",
    "            x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
    "        if sequence_data:\n",
    "            for seq_name in sequence_data:\n",
    "                if 'x_num' in sequence_data[seq_name]:\n",
    "                    sequence_data[seq_name]['x_num'] = {\n",
    "                        k: v.to(device) for k, v in sequence_data[seq_name]['x_num'].items()\n",
    "                    }\n",
    "                if 'x_cat' in sequence_data[seq_name]:\n",
    "                    sequence_data[seq_name]['x_cat'] = {\n",
    "                        k: v.to(device) for k, v in sequence_data[seq_name]['x_cat'].items()\n",
    "                    }\n",
    "                if 'mask' in sequence_data[seq_name]:\n",
    "                    sequence_data[seq_name]['mask'] = sequence_data[seq_name]['mask'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向き計算\n",
    "        outputs = model(x_num=x_num, x_cat=x_cat, sequence_data=sequence_data)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 後向き計算\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 統計情報の更新\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # プログレスバー更新\n",
    "        progress_bar.set_postfix({\n",
    "            'Loss': f'{loss.item():.4f}',\n",
    "            'Acc': f'{100.*correct/total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(dataloader), 100. * correct / total\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Validation\"):\n",
    "            x_num = batch['x_num']\n",
    "            x_cat = batch['x_cat']\n",
    "            sequence_data = batch['sequence_data']\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # GPU転送\n",
    "            if x_num:\n",
    "                x_num = {k: v.to(device) for k, v in x_num.items()}\n",
    "            if x_cat:\n",
    "                x_cat = {k: v.to(device) for k, v in x_cat.items()}\n",
    "            if sequence_data:\n",
    "                for seq_name in sequence_data:\n",
    "                    if 'x_num' in sequence_data[seq_name]:\n",
    "                        sequence_data[seq_name]['x_num'] = {\n",
    "                            k: v.to(device) for k, v in sequence_data[seq_name]['x_num'].items()\n",
    "                        }\n",
    "                    if 'x_cat' in sequence_data[seq_name]:\n",
    "                        sequence_data[seq_name]['x_cat'] = {\n",
    "                            k: v.to(device) for k, v in sequence_data[seq_name]['x_cat'].items()\n",
    "                        }\n",
    "                    if 'mask' in sequence_data[seq_name]:\n",
    "                        sequence_data[seq_name]['mask'] = sequence_data[seq_name]['mask'].to(device)\n",
    "            \n",
    "            outputs = model(x_num=x_num, x_cat=x_cat, sequence_data=sequence_data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return total_loss / len(dataloader), 100. * correct / total, all_predictions, all_labels\n",
    "\n",
    "print(\"訓練関数定義完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練実行\n",
    "NUM_EPOCHS = 20\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "print(\"訓練開始...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # 訓練\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # 検証\n",
    "    val_loss, val_acc, val_predictions, val_labels = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    # 学習率スケジューラー更新\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # 結果記録\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # ベストモデル保存\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'model_params': model_params,\n",
    "            'preprocessing_params': dataset.get_preprocessing_params()\n",
    "        }, '../models/best_model.pt')\n",
    "        print(f\"新しいベストモデルを保存 (Val Loss: {val_loss:.4f})\")\n",
    "\n",
    "print(\"訓練完了!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線の可視化\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# 損失\n",
    "ax1.plot(train_losses, label='Train Loss', color='blue')\n",
    "ax1.plot(val_losses, label='Validation Loss', color='red')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# 精度\n",
    "ax2.plot(train_accs, label='Train Accuracy', color='blue')\n",
    "ax2.plot(val_accs, label='Validation Accuracy', color='red')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータでの最終評価\n",
    "print(\"テストデータでの評価...\")\n",
    "\n",
    "# ベストモデルの読み込み\n",
    "checkpoint = torch.load('../models/best_model.pt', map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# テスト\n",
    "test_loss, test_acc, test_predictions, test_labels = validate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# 詳細な分類報告\n",
    "print(\"\\n分類レポート:\")\n",
    "print(classification_report(test_labels, test_predictions, \n",
    "                          target_names=['何もしない', '買い', '売り']))\n",
    "\n",
    "# 混同行列\n",
    "cm = confusion_matrix(test_labels, test_predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['何もしない', '買い', '売り'],\n",
    "            yticklabels=['何もしない', '買い', '売り'])\n",
    "plt.title('混同行列 (テストデータ)')\n",
    "plt.ylabel('実際のクラス')\n",
    "plt.xlabel('予測クラス')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス別の予測性能分析\n",
    "class_names = ['何もしない', '買い', '売り']\n",
    "class_predictions = {i: [] for i in range(3)}\n",
    "class_true_labels = {i: [] for i in range(3)}\n",
    "\n",
    "for true_label, pred_label in zip(test_labels, test_predictions):\n",
    "    class_predictions[true_label].append(pred_label)\n",
    "    class_true_labels[true_label].append(true_label)\n",
    "\n",
    "print(\"クラス別詳細分析:\")\n",
    "for i, class_name in enumerate(class_names):\n",
    "    if len(class_predictions[i]) > 0:\n",
    "        class_acc = sum(1 for t, p in zip(class_true_labels[i], class_predictions[i]) if t == p) / len(class_predictions[i])\n",
    "        print(f\"{class_name}: {len(class_predictions[i])} サンプル, 精度: {class_acc*100:.1f}%\")\n",
    "    else:\n",
    "        print(f\"{class_name}: 0 サンプル\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの最終保存\n",
    "final_model_path = '../models/foregues_model_final.pt'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_params': model_params,\n",
    "    'preprocessing_params': dataset.get_preprocessing_params(),\n",
    "    'training_params': {\n",
    "        'th1': TH1,\n",
    "        'th2': TH2,\n",
    "        'sequence_length': SEQUENCE_LENGTH,\n",
    "        'prediction_period': PREDICTION_PERIOD,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'num_epochs': NUM_EPOCHS\n",
    "    },\n",
    "    'test_results': {\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_acc,\n",
    "        'classification_report': classification_report(test_labels, test_predictions, \n",
    "                                                     target_names=class_names, output_dict=True)\n",
    "    }\n",
    "}, final_model_path)\n",
    "\n",
    "print(f\"最終モデルを保存: {final_model_path}\")\n",
    "print(\"訓練とテストが完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foregues",
   "language": "python",
   "name": "foregues"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
