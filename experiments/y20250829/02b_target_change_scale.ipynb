{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### まずは有効なすべてのTickerとTimestampの組合せを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 200\n",
    "RADIUS = 1\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_data(df):\n",
    "    target_indices = []\n",
    "    timestamps = []\n",
    "    target_changes = []\n",
    "    \n",
    "    for i in range(WINDOW, len(df)):\n",
    "        target_indices.append(i)\n",
    "        timestamps.append(df.iloc[i].name)\n",
    "        target_changes.append(np.log(df.iloc[i]['Close'] + 1e-10) - np.log(df.iloc[i]['Open'] + 1e-10))\n",
    "        \n",
    "    return target_indices, timestamps, target_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "input_dir = 'history'\n",
    "\n",
    "def process_file(filename, input_dir):\n",
    "    \"\"\"各ファイルを処理する関数\"\"\"\n",
    "    if not filename.endswith('.joblib'):\n",
    "        return None\n",
    "    \n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    history_data = joblib.load(file_path)\n",
    "    \n",
    "    ticker = history_data['ticker']\n",
    "    history_df = history_data['history_df']\n",
    "    \n",
    "    # データの作成\n",
    "    target_indices, timestamps, target_changes = generate_data(history_df)\n",
    "    \n",
    "    return {\n",
    "        'tickers': [ticker] * len(target_indices),\n",
    "        'target_indices': target_indices,\n",
    "        'timestamps': timestamps,\n",
    "        'target_changes': target_changes\n",
    "    }\n",
    "\n",
    "# 並列処理の実行\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith('.joblib')]\n",
    "\n",
    "# n_jobs=-1で全CPUコアを使用\n",
    "results = Parallel(n_jobs=-1)(\n",
    "    delayed(process_file)(filename, input_dir) \n",
    "    for filename in tqdm(files, desc=\"Processing files\")\n",
    ")\n",
    "\n",
    "# 結果の結合\n",
    "tickers = []\n",
    "target_indices = []\n",
    "timestamps = []\n",
    "target_changes = []\n",
    "\n",
    "for result in results:\n",
    "    if result is not None:\n",
    "        tickers.extend(result['tickers'])\n",
    "        target_indices.extend(result['target_indices'])\n",
    "        timestamps.extend(result['timestamps'])\n",
    "        target_changes.extend(result['target_changes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### test_start_timestamp よりも前のデータを学習に使用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "test_start_timestamp = pd.Timestamp(datetime.now() - timedelta(days=365)).tz_localize('Asia/Tokyo')\n",
    "\n",
    "is_train = [timestamp < test_start_timestamp for timestamp in timestamps]\n",
    "train_indices = np.arange(len(tickers))[is_train]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_indices, val_indices = train_test_split(train_indices)\n",
    "\n",
    "is_test = [timestamp >= test_start_timestamp for timestamp in timestamps]\n",
    "test_indices = np.arange(len(tickers))[is_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(target_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / np.nanstd(target_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foregues",
   "language": "python",
   "name": "foregues"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
