{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('jq_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "データフレームdfがあります。  \n",
    "dfにはDisclosedDateというカラムがあります。これが今日のちょうど一年前までを学習用（一部を検証用に分割）、それ以降をテスト用として使用します。  \n",
    "dfには'ftn.'で始まるカラムがあり、これらは数値特徴量です。NaNを欠損値として処理します。  \n",
    "dfには'ftc.'で始まるカラムがあり、これらはカテゴリ特徴量です。Noneを欠損値として処理します。  \n",
    "これらの特徴量をxgboostで学習します。ラベルは'label'というカラム（数値）を使用します。前進法で特徴量選択を行います。アーリーストッピングも実装します。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. データの分割\n",
    "def split_data_by_date(df):\n",
    "    \"\"\"\n",
    "    今日の1年前を基準に学習用とテスト用にデータを分割\n",
    "    \"\"\"\n",
    "    today = datetime.now()\n",
    "    one_year_ago = today - timedelta(days=365)\n",
    "    \n",
    "    # DisclosedDateをdatetime型に変換\n",
    "    df['DisclosedDate'] = pd.to_datetime(df['DisclosedDate'])\n",
    "    \n",
    "    # labelのNaNを0に置換\n",
    "    df['label'] = df['label'].fillna(0)\n",
    "    print(f\"labelのNaN件数: {df['label'].isna().sum()} 件 (0に置換済み)\")\n",
    "    \n",
    "    # 学習用とテスト用に分割\n",
    "    train_df = df[df['DisclosedDate'] <= one_year_ago].copy()\n",
    "    test_df = df[df['DisclosedDate'] > one_year_ago].copy()\n",
    "    \n",
    "    print(f\"学習用データ: {len(train_df)} 件 ({train_df['DisclosedDate'].min()} ~ {train_df['DisclosedDate'].max()})\")\n",
    "    print(f\"テスト用データ: {len(test_df)} 件 ({test_df['DisclosedDate'].min()} ~ {test_df['DisclosedDate'].max()})\")\n",
    "    \n",
    "    # labelの分布を確認\n",
    "    print(f\"\\n学習用ラベルの統計:\")\n",
    "    print(f\"  平均: {train_df['label'].mean():.4f}\")\n",
    "    print(f\"  標準偏差: {train_df['label'].std():.4f}\")\n",
    "    print(f\"  最小値: {train_df['label'].min():.4f}\")\n",
    "    print(f\"  最大値: {train_df['label'].max():.4f}\")\n",
    "    print(f\"  ゼロの割合: {(train_df['label'] == 0).mean():.2%}\")\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. データを時系列で分割\n",
    "train_df, test_df = split_data_by_date(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 特徴量の前処理\n",
    "def preprocess_features(train_df, test_df):\n",
    "    \"\"\"\n",
    "    数値特徴量とカテゴリ特徴量の前処理\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # 特徴量カラムの識別\n",
    "    numeric_cols = [col for col in train_df.columns if col.startswith('ftn.')]\n",
    "    categorical_cols = [col for col in train_df.columns if col.startswith('ftc.')]\n",
    "    \n",
    "    print(f\"数値特徴量: {len(numeric_cols)} 個\")\n",
    "    print(f\"カテゴリ特徴量: {len(categorical_cols)} 個\")\n",
    "    \n",
    "    # 処理後のデータフレーム\n",
    "    train_processed = train_df.copy()\n",
    "    test_processed = test_df.copy()\n",
    "    \n",
    "    # 数値特徴量の無限大処理（inf, -infをNaNに変換）\n",
    "    # XGBoostはNaNを自動的にmissingとして扱うため、fillnaは不要\n",
    "    for col in numeric_cols:\n",
    "        # 正の無限大と負の無限大をNaNに置換\n",
    "        train_processed[col] = train_processed[col].replace([np.inf, -np.inf], np.nan)\n",
    "        test_processed[col] = test_processed[col].replace([np.inf, -np.inf], np.nan)\n",
    "    \n",
    "    # カテゴリ特徴量の処理\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        # Noneを'missing'に置換\n",
    "        train_processed[col] = train_processed[col].fillna('missing')\n",
    "        test_processed[col] = test_processed[col].fillna('missing')\n",
    "        \n",
    "        # Label Encoding\n",
    "        le = LabelEncoder()\n",
    "        # 学習データで fit\n",
    "        train_values = train_processed[col].astype(str)\n",
    "        le.fit(train_values)\n",
    "        \n",
    "        # 変換\n",
    "        train_processed[col] = le.transform(train_values)\n",
    "        \n",
    "        # テストデータの未知のカテゴリを処理\n",
    "        test_values = test_processed[col].astype(str)\n",
    "        test_values_encoded = []\n",
    "        for val in test_values:\n",
    "            if val in le.classes_:\n",
    "                test_values_encoded.append(le.transform([val])[0])\n",
    "            else:\n",
    "                test_values_encoded.append(-1)  # 未知のカテゴリ\n",
    "        test_processed[col] = test_values_encoded\n",
    "        \n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    return train_processed, test_processed, numeric_cols + categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 特徴量の前処理\n",
    "train_processed, test_processed, feature_cols = preprocess_features(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 学習データをさらに訓練用と検証用に分割\n",
    "X_train_full = train_processed[feature_cols]\n",
    "y_train_full = train_processed['label']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\n訓練データ: {len(X_train)} 件\")\n",
    "print(f\"検証データ: {len(X_val)} 件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [col for col in feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. XGBoostモデルの学習（アーリーストッピング付き）\n",
    "def train_xgboost_with_early_stopping(X_train, y_train, X_val, y_val, selected_features):\n",
    "    \"\"\"\n",
    "    選択された特徴量でXGBoostモデルを学習\n",
    "    \"\"\"\n",
    "    print(\"\\n=== XGBoostモデルの学習（アーリーストッピング付き） ===\")\n",
    "    \n",
    "    # DMatrix形式に変換\n",
    "    dtrain = xgb.DMatrix(X_train[selected_features], label=y_train)\n",
    "    dval = xgb.DMatrix(X_val[selected_features], label=y_val)\n",
    "    \n",
    "    # パラメータ設定\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'rmse',\n",
    "        'max_depth': 8,\n",
    "        'learning_rate': 0.05,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'min_child_weight': 3,\n",
    "        'gamma': 0.1,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 1.0,\n",
    "        'seed': 42\n",
    "    }\n",
    "    \n",
    "    # アーリーストッピング付きで学習\n",
    "    evals_result = {}\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "        early_stopping_rounds=50,\n",
    "        evals_result=evals_result,\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n最適なラウンド数: {model.best_iteration}\")\n",
    "    print(f\"最良の検証スコア (RMSE): {model.best_score:.4f}\")\n",
    "    \n",
    "    return model, evals_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 選択された特徴量でモデルを再学習（アーリーストッピング付き）\n",
    "final_model, evals_result = train_xgboost_with_early_stopping(\n",
    "    X_train, y_train, \n",
    "    X_val, y_val, \n",
    "    selected_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# モデルの保存\n",
    "joblib.dump(final_model, 'jq_model.joblib')\n",
    "joblib.dump(selected_features, 'jq_selected_features.joblib')\n",
    "\n",
    "# 特徴量選択結果の保存\n",
    "# feature_selection_results = {\n",
    "#     'selected_features': selected_features,\n",
    "#     'final_score': selection_score,\n",
    "#     'feature_count': len(selected_features),\n",
    "#     'original_feature_count': len(feature_cols)\n",
    "# }\n",
    "\n",
    "# with open('jq_feature_selection_results.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(feature_selection_results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# print(f\"\\nモデルと特徴量選択結果を保存しました:\")\n",
    "# print(f\"  - モデル: jq_model.joblib\")\n",
    "# print(f\"  - 選択特徴量: jq_selected_features.joblib\") \n",
    "# print(f\"  - 選択結果: feature_selection_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. モデルの評価\n",
    "def evaluate_model(model, X_test, y_test, selected_features):\n",
    "    \"\"\"\n",
    "    テストデータでモデルを評価\n",
    "    \"\"\"\n",
    "    dtest = xgb.DMatrix(X_test[selected_features])\n",
    "    y_pred = model.predict(dtest)\n",
    "    \n",
    "    # RMSEを計算（squared=Falseが使えない場合の代替方法）\n",
    "    try:\n",
    "        # 新しいバージョンのscikit-learn\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    except TypeError:\n",
    "        # 古いバージョンのscikit-learn：MSEの平方根を取る\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\n=== テストデータでの評価結果 ===\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'predictions': y_pred\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. テストデータで評価\n",
    "X_test = test_processed[feature_cols]\n",
    "y_test = test_processed['label']\n",
    "\n",
    "results = evaluate_model(final_model, X_test, y_test, selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 特徴量の重要度を表示\n",
    "def plot_feature_importance(model, selected_features, top_n=20):\n",
    "    \"\"\"\n",
    "    特徴量の重要度を表示\n",
    "    \"\"\"\n",
    "    importance = model.get_score(importance_type='gain')\n",
    "    \n",
    "    # DataFrameに変換\n",
    "    importance_df = pd.DataFrame(\n",
    "        [(f, importance.get(f'f{i}', 0)) for i, f in enumerate(selected_features)],\n",
    "        columns=['feature', 'importance']\n",
    "    )\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False).head(top_n)\n",
    "    \n",
    "    print(f\"\\n=== Top {top_n} 重要な特徴量 ===\")\n",
    "    for idx, row in importance_df.iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.2f}\")\n",
    "    \n",
    "    return importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 特徴量の重要度を表示\n",
    "importance_df = plot_feature_importance(final_model, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線の可視化（オプション）\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(evals_result['train']['rmse'], label='Train RMSE')\n",
    "plt.plot(evals_result['val']['rmse'], label='Validation RMSE')\n",
    "plt.xlabel('Boosting Rounds')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "x = y_test\n",
    "y = results['predictions']\n",
    "\n",
    "sns.scatterplot(x=x, y=y, s=5, color=\".15\")\n",
    "sns.histplot(x=x, y=y, bins=50, pthresh=.1, cmap=\"mako\")\n",
    "sns.kdeplot(x=x, y=y, levels=5, color=\"w\", linewidths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量選択結果の詳細分析\n",
    "def analyze_feature_selection_results(original_features, selected_features, final_model):\n",
    "    \"\"\"\n",
    "    特徴量選択結果の詳細分析\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"特徴量選択結果の詳細分析\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 基本統計\n",
    "    print(f\"元の特徴量数: {len(original_features)}\")\n",
    "    print(f\"選択された特徴量数: {len(selected_features)}\")\n",
    "    print(f\"削減率: {(1 - len(selected_features)/len(original_features))*100:.1f}%\")\n",
    "    \n",
    "    # 特徴量タイプ別の分析\n",
    "    original_numeric = [f for f in original_features if f.startswith('ftn.')]\n",
    "    original_categorical = [f for f in original_features if f.startswith('ftc.')]\n",
    "    selected_numeric = [f for f in selected_features if f.startswith('ftn.')]\n",
    "    selected_categorical = [f for f in selected_features if f.startswith('ftc.')]\n",
    "    \n",
    "    print(f\"\\n特徴量タイプ別:\")\n",
    "    print(f\"  数値特徴量: {len(original_numeric)} → {len(selected_numeric)} ({len(selected_numeric)/len(original_numeric)*100:.1f}%)\")\n",
    "    print(f\"  カテゴリ特徴量: {len(original_categorical)} → {len(selected_categorical)} ({len(selected_categorical)/len(original_categorical)*100:.1f}%)\")\n",
    "    \n",
    "    # 重要度の上位特徴量\n",
    "    importance = final_model.get_score(importance_type='gain')\n",
    "    importance_df = pd.DataFrame(\n",
    "        [(f, importance.get(f'f{i}', 0)) for i, f in enumerate(selected_features)],\n",
    "        columns=['feature', 'importance']\n",
    "    )\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\n最も重要な特徴量 Top 10:\")\n",
    "    for i, (_, row) in enumerate(importance_df.head(10).iterrows()):\n",
    "        feature_type = \"数値\" if row['feature'].startswith('ftn.') else \"カテゴリ\"\n",
    "        print(f\"  {i+1:2d}. {row['feature']} ({feature_type}): {row['importance']:.2f}\")\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# 分析実行\n",
    "importance_analysis = analyze_feature_selection_results(feature_cols, selected_features, final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foregues",
   "language": "python",
   "name": "foregues"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
